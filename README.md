# AI-Transparency-Proposal
Proposal to eliminate modes of model collapse, information source uncertainty, and plagiarism using simple text lookup methods. 

## Background: The Problem

Due to the prevalence of unlabeled, AI generated text on the internet, it has been increasingly difficult to discern "good" from "bad" data.

This is a problem for several reasons:
* Model Collapse - Generative AI being trained on output from itself. Companies can use internal data to determine if text was previousl generated by their model. Other parties do not have this luxury (See GROK).
* Source Veracity - Teachers and institutions of higher education are forced to resort to innacurate/faulty solutions that claim to "detect AI data". This can cause more harm than good due to misunderstandings about the nature of AI.
* Transparency - AI companies cannot be held accountable for data they create that is unlabeled. This removes an opportunity for improvement based on public feedback.

## Proposed Solution: Public Standardized "did you make this" API
  * AI companies already store all generated text. Create a standard API endpoint for companies to implement that allows a "yes"/"no" response by performing a quick lookup.
  * 







The term "AI" is used loosely in this document to refer to text based generative AI models e.g. Chat GPT, Copilot, Grok.
